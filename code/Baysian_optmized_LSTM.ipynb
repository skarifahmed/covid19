{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helper_lstm import *\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath='alldata/'\n",
    "country = [f for f in listdir(datapath) if isfile(join(datapath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate,num_of_layers,num_hidden_nodes,activation, batch_size,dropout,timesteps=1):\n",
    "      \n",
    "    train,val,test,sc=get_train_test(series)\n",
    "    #named blackbox becuase it represents the structure\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "  \n",
    "    # Loop for training data\n",
    "    for i in range(timesteps,train.shape[0]):\n",
    "        X_train.append(train[i-timesteps:i])\n",
    "        Y_train.append(train[i][0])\n",
    "    X_train,Y_train = np.array(X_train),np.array(Y_train)\n",
    "  \n",
    "    # Loop for val data\n",
    "    for i in range(timesteps,val.shape[0]):\n",
    "        X_val.append(val[i-timesteps:i])\n",
    "        Y_val.append(val[i][0])\n",
    "    X_val,Y_val = np.array(X_val),np.array(Y_val)\n",
    "    \n",
    "    print('Creating Model')\n",
    "    model = create_model(X_train,learning_rate=learning_rate,\n",
    "                         num_of_layers=num_of_layers,\n",
    "                         num_hidden_nodes=num_hidden_nodes,\n",
    "                         activation=activation,\n",
    "                         dropout=dropout\n",
    "                        )\n",
    "     \n",
    "    blackbox = model.fit(X_train,Y_train,epochs = 5000,batch_size = batch_size,validation_data = (X_val, Y_val),verbose = 0,callbacks=callbacks_list)\n",
    "    \n",
    "    accuracy = blackbox.history['val_loss'][-1]\n",
    "    #accuracy = blackbox.history['mean_squared_error'][-1]\n",
    "    # Print the classification accuracy.\n",
    "    print(accuracy)\n",
    "    #print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    #tensorflow.reset_default_graph()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ase072\\Documents\\Research\\ratnabali\\code_github\\helper_lstm.py:53: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
      "  dateparse = lambda dates: [pd.datetime.strptime(d, '%d-%m-%Y') for d in dates]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "0.009871192514273255 19 26 sigmoid 0.1982903636480131\n",
      "Epoch 00086: early stopping\n",
      "0.47692373394966125\n",
      "\n",
      "Creating Model\n",
      "0.0002901617266778567 13 186 relu 0.46180961130260206\n",
      "Epoch 00107: early stopping\n",
      "0.4712564218789339\n",
      "\n",
      "Creating Model\n",
      "0.0021923067754737757 16 142 sigmoid 0.1691081661342563\n",
      "Epoch 00105: early stopping\n",
      "0.45859234035015106\n",
      "\n",
      "Creating Model\n",
      "0.0027911267473149284 19 64 sigmoid 0.09923851862033653\n",
      "Epoch 00095: early stopping\n",
      "0.4943162966519594\n",
      "\n",
      "Creating Model\n",
      "0.0047384302791815165 17 148 relu 0.10085474838335182\n",
      "Epoch 00081: early stopping\n",
      "0.48274939383069676\n",
      "\n",
      "Creating Model\n",
      "0.006386996394990391 8 146 sigmoid 0.1258212888673371\n",
      "Epoch 00096: early stopping\n",
      "0.4685603454709053\n",
      "\n",
      "Creating Model\n",
      "0.002052499346059442 15 5 sigmoid 0.039974975180523405\n",
      "Epoch 00143: early stopping\n",
      "0.4591938691834609\n",
      "\n",
      "Creating Model\n",
      "0.00010275590774634764 18 163 relu 0.26822978216882726\n",
      "Epoch 00175: early stopping\n",
      "0.4561147491137187\n",
      "\n",
      "Creating Model\n",
      "0.004390561144393705 6 162 relu 0.11175750057679526\n",
      "Epoch 00087: early stopping\n",
      "0.4630810668071111\n",
      "\n",
      "Creating Model\n",
      "0.0001480280917351551 16 89 sigmoid 0.3285781434408338\n",
      "Epoch 00095: early stopping\n",
      "0.4789116010069847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting up an early stop\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=80,  verbose=1, mode='min')\n",
    "#earlystop = EarlyStopping(monitor='mean_squared_error', min_delta=0.0001, patience=80,  verbose=1, mode='min')\n",
    "callbacks_list = [earlystop]\n",
    "iteration=500\n",
    "for country_file in country:\n",
    "    country_name=country_file[:-4]\n",
    "    # Train Val Test Split\n",
    "    series=get_data(country_name)\n",
    "    gp_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            n_calls=iteration,\n",
    "                            noise= 0.01,\n",
    "                            n_jobs=-1,\n",
    "                            kappa = 5)\n",
    "   \n",
    "\n",
    "    f = open('model/'+country_name+'_lstm.pckl', 'wb')\n",
    "    pickle.dump(gp_result, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
